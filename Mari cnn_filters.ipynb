{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Interpreting Convolutional Kernels\n",
    "\n",
    "This example shows how to analyze kernel activations for given input texts or with hypothetical word sequences.\n",
    "The example is based on our previous IMDB movie review sentiment classification notes. The relevant information starts from the NN model definition, reading the data and pretrained word embeddings is identical/similar to what we have seen previously.\n",
    "\n",
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '&#2;\\n******CHEMICAL BANK CUTS PRIME RATE TO 9.25 PCT FROM 9.75 PCT, EFFECTIVE IMMEDIATELY\\nBlah blah blah.\\n&#3;', 'class': 'interest'}\n",
      "['&#2;\\n******CHEMICAL BANK CUTS PRIME RATE TO 9.25 PCT FROM 9.75 PCT, EFFECTIVE IMMEDIATELY\\nBlah blah blah.\\n&#3;', '&#2;\\nUNICORP CANADA&lt;UNI.A> CUTS PUROLATOR&lt;PCC> STAKE\\nWASHINGTON, March 4 - Unicorp Canada Corp told the\\nSecurities and Exchange Commission it cut its stake in\\nPurolator Courier Corp to 286,500 shares, or 3.7 pct of the\\ntotal outstanding, from 962,400 shares, or 12.4 pct.\\nUnicorp, a management and investment holding company\\ncontrolled by its chairman, George Mann, said it sold 675,900\\nPurolator common shares on March 2 and 3 at 34.782 and 34.750\\ndlrs a share.\\nPurolator agreed this past weekend to be acquired by\\nmanagers of its U.S. courier business and E.F. Hutton LBO Inc\\nin a leveraged buyout valued at 265 mln dlrs.\\nReuter\\n&#3;']\n",
      "['interest', 'acq']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "with open(\"data/reuters_51cls.json\") as f: #muutettu imdb --> reuters (ei taida toimia)\n",
    "    data=json.load(f)\n",
    "random.shuffle(data) \n",
    "print(data[0])\n",
    "\n",
    "# We need to gather the texts, into a list\n",
    "texts=[one_example[\"text\"] for one_example in data]\n",
    "labels=[one_example[\"class\"] for one_example in data]\n",
    "print(texts[:2])\n",
    "print(labels[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use gensim to read the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words from embedding model: 20000\n",
      "First 50 words: [',', 'the', '.', 'and', 'of', 'to', 'in', 'a', '\"', ':', ')', 'that', '(', 'is', 'for', 'on', '*', 'with', 'as', 'it', 'The', 'or', 'was', \"'\", \"'s\", 'by', 'from', 'at', 'I', 'this', 'you', '/', 'are', '=', 'not', '-', 'have', '?', 'be', 'which', ';', 'all', 'his', 'has', 'one', 'their', 'about', 'but', 'an', '|']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "vector_model=KeyedVectors.load_word2vec_format(\"/home/bio/wiki-news-300d-1M.vec\", binary=False, limit=20000)\n",
    "#(muokattu: ennen \"/data/wiki..\")\n",
    "\n",
    "# sort based on the index to make sure they are in the correct order\n",
    "words=[k for k,v in sorted(vector_model.vocab.items(), key=lambda x:x[1].index)]\n",
    "print(\"Words from embedding model:\",len(words))\n",
    "print(\"First 50 words:\",words[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the vectors\n",
    "\n",
    "- Easier to learn on top of these vectors when the magnitude does not vary much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization: [-0.0234 -0.0268 -0.0838  0.0386 -0.0321  0.0628  0.0281 -0.0252  0.0269\n",
      " -0.0063]\n",
      "After normalization: [-0.0163762  -0.01875564 -0.05864638  0.02701372 -0.02246478  0.04394979\n",
      "  0.01966543 -0.0176359   0.01882563 -0.00440898]\n"
     ]
    }
   ],
   "source": [
    "print(\"Before normalization:\",vector_model.get_vector(\"in\")[:10])\n",
    "vector_model.init_sims(replace=True)\n",
    "print(\"After normalization:\",vector_model.get_vector(\"in\")[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text analyzer and vectorizer\n",
    "\n",
    "- When we use an embedding layer (keras.layers.Embedding) the input data must be a sequence, not a bag-of-words vector\n",
    "- You can use CountVectorizer only as an analyzer without building the feature matrix\n",
    "- We will then build the vectorizer part later ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHEMICAL', 'BANK', 'CUTS', 'PRIME', 'RATE', 'TO', '25', 'PCT', 'FROM', '75', 'PCT', 'EFFECTIVE', 'IMMEDIATELY', 'Blah', 'blah', 'blah']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy\n",
    "analyzer=CountVectorizer(lowercase=False).build_analyzer() # includes tokenizer and preprocessing\n",
    "print(analyzer(texts[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand the vocabulary using words from the embedding model\n",
    "\n",
    "- The embedding model usually knows more words than the task specific model, because it has seen a lot more data\n",
    "- If you wish, you can use the embedding model vocabulary to expand the task specific one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words from embedding model: 19497\n"
     ]
    }
   ],
   "source": [
    "# init the vectorizer vocabulary using words from the embedding model\n",
    "def init_vocabulary(vocab, text, text_analyzer):\n",
    "    for word in analyzer(text):\n",
    "        # Only use pretrained vocabulary\n",
    "        if word in vector_model.vocab:\n",
    "            vocab.setdefault(word, len(vocab))\n",
    "    return vocab\n",
    "\n",
    "words_from_model=\" \".join(words[:20000]) # use 20K words from the embedding model to initialize the vocabulary --> expands the learned vocabulary\n",
    "vocabulary={\"<SPECIAL>\": 0} # zero has a special meaning in sequence models, prevent using it for a normal word\n",
    "vocabulary=init_vocabulary(vocabulary, words_from_model, analyzer)\n",
    "print(\"Words from embedding model:\",len(vocabulary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer\n",
    "\n",
    "- Build a dictionary to turn words into numbers, here we use the one which we initialized with the embedding model\n",
    "- Vectorizing a sequence: In our data each example is a list of words, we need to turn each example into list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in vocabulary: 19497\n",
      "Vectorized data shape: (9465,)\n",
      "First example vectorized: [8932, 319, 18599, 3514, 12239, 12239]\n",
      "First example text: ['TO', '25', 'FROM', '75', 'blah', 'blah']\n"
     ]
    }
   ],
   "source": [
    "def vectorizer(vocab, texts):\n",
    "    vectorized_data=[] # turn text into numbers based on our vocabulary mapping\n",
    "    for one_example in texts:\n",
    "        vectorized_example=[]\n",
    "        for word in analyzer(one_example):\n",
    "            # Only use pretrained vocabulary\n",
    "            if word in vector_model.vocab:\n",
    "                vectorized_example.append(vocab[word])\n",
    "            #vocab.setdefault(word, len(vocab)) # add word to our vocabulary if it does not exist\n",
    "            #vectorized_example.append(vocab[word])\n",
    "        vectorized_data.append(vectorized_example)\n",
    "    \n",
    "    vectorized_data=numpy.array(vectorized_data) # turn python list into numpy matrix\n",
    "    return vectorized_data, vocab\n",
    "\n",
    "vectorized_data, vocabulary=vectorizer(vocabulary, texts)\n",
    "\n",
    "# now vectorized data is the same as feature_matrix, but in different format\n",
    "print(\"Words in vocabulary:\",len(vocabulary))\n",
    "print(\"Vectorized data shape:\",vectorized_data.shape)\n",
    "print(\"First example vectorized:\",vectorized_data[0])\n",
    "inversed_vocabulary={value:key for key, value in vocabulary.items()} # inverse the dictionary\n",
    "print(\"First example text:\",[inversed_vocabulary[idx] for idx in vectorized_data[0]])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels into onehot vectors\n",
    "\n",
    "- Same as in the original BOW classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_numbers shape= (9465,)\n",
      "class_numbers [21  0 11 ... 11 11 14]\n",
      "class labels ['acq' 'alum' 'bop' 'carcass' 'cocoa' 'coffee' 'copper' 'cotton' 'cpi'\n",
      " 'crude' 'dlr' 'earn' 'fuel' 'gas' 'gnp' 'gold' 'grain' 'heat' 'housing'\n",
      " 'income' 'instal-debt' 'interest' 'ipi' 'iron-steel' 'jobs' 'lead' 'lei'\n",
      " 'livestock' 'lumber' 'meal-feed' 'money-fx' 'money-supply' 'nat-gas'\n",
      " 'oilseed' 'orange' 'pet-chem' 'potato' 'reserves' 'retail' 'rubber'\n",
      " 'ship' 'silver' 'strategic-metal' 'sugar' 'tea' 'tin' 'trade' 'veg-oil'\n",
      " 'wpi' 'yen' 'zinc']\n",
      "classes_1hot [[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "label_encoder=LabelEncoder() #Turns class labels into integers\n",
    "one_hot_encoder=OneHotEncoder(sparse=False) #Turns class integers into one-hot encoding\n",
    "class_numbers=label_encoder.fit_transform(labels)\n",
    "print(\"class_numbers shape=\",class_numbers.shape)\n",
    "print(\"class_numbers\",class_numbers)\n",
    "print(\"class labels\",label_encoder.classes_)\n",
    "#And now yet the one-hot encoding\n",
    "classes_1hot=one_hot_encoder.fit_transform(class_numbers.reshape(-1,1))\n",
    "print(\"classes_1hot\",classes_1hot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network\n",
    "\n",
    "- First we need to create an embedding matrix which we can then plug into the neural network\n",
    "- The embedding matrix must follow the order from the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained vectors for 19496 words.\n",
      "Shape of pretrained embeddings: (19497, 300)\n",
      "Vector for the word 'in': [-0.0163762  -0.01875564 -0.05864638  0.02701372 -0.02246478  0.04394979\n",
      "  0.01966543 -0.0176359   0.01882563 -0.00440898]\n"
     ]
    }
   ],
   "source": [
    "def load_pretrained_embeddings(vocab, embedding_model):\n",
    "    \"\"\" vocab: vocabulary from our data vectorizer, embedding_model: model loaded with gensim \"\"\"\n",
    "    pretrained_embeddings=numpy.random.uniform(low=-0.05, high=0.05, size=(len(vocab),embedding_model.vectors.shape[1])) # initialize new matrix (words x embedding dim)\n",
    "    found=0\n",
    "    for word,idx in vocab.items():\n",
    "        if word in embedding_model.vocab:\n",
    "            pretrained_embeddings[idx]=embedding_model.get_vector(word)\n",
    "            found+=1\n",
    "            \n",
    "    print(\"Found pretrained vectors for {found} words.\".format(found=found))\n",
    "    return pretrained_embeddings\n",
    "\n",
    "pretrained=load_pretrained_embeddings(vocabulary, vector_model)\n",
    "print(\"Shape of pretrained embeddings:\",pretrained.shape)\n",
    "print(\"Vector for the word 'in':\",pretrained[vocabulary[\"in\"]][:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Sequential input\n",
    "\n",
    "- Remember how the shape of the input data matrix had undefined number of columns\n",
    "- Now we must make it into fixed size (same for each example)\n",
    "- Padding: include zeros until you reach the correct size\n",
    "- You will hear more about this next week!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marsalv/.local/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old shape: (9465,)\n",
      "New shape: (9465, 970)\n",
      "First example: [ 8932   319 18599  3514 12239 12239     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "### Only needed for me, not to block the whole GPU, you don't need this stuff\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))\n",
    "### ---end of weird stuff\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "print(\"Old shape:\", vectorized_data.shape)\n",
    "vectorized_data_padded=pad_sequences(vectorized_data, padding='post')\n",
    "print(\"New shape:\", vectorized_data_padded.shape)\n",
    "print(\"First example:\", vectorized_data_padded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple network with a single convolutional layer with window size of 2 words (bigrams), 50 kernels and global max pooling (only the maximum value from each kernel is preserved). We create a separate model with the CNN layer as the output. This model shares weights with the actual model and can be used in analysing the kernel activations in each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 970)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 970, 300)          5849100   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 969, 20)           12020     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 51)                1071      \n",
      "=================================================================\n",
      "Total params: 5,862,191\n",
      "Trainable params: 13,091\n",
      "Non-trainable params: 5,849,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 8518 samples, validate on 947 samples\n",
      "Epoch 1/6\n",
      "8518/8518 [==============================] - 63s 7ms/step - loss: 2.4151 - acc: 0.4631 - val_loss: 1.7932 - val_acc: 0.5649\n",
      "Epoch 2/6\n",
      "8518/8518 [==============================] - 64s 8ms/step - loss: 1.5877 - acc: 0.5836 - val_loss: 1.5213 - val_acc: 0.6135\n",
      "Epoch 3/6\n",
      "8518/8518 [==============================] - 66s 8ms/step - loss: 1.3304 - acc: 0.6807 - val_loss: 1.3307 - val_acc: 0.7001\n",
      "Epoch 4/6\n",
      "8518/8518 [==============================] - 69s 8ms/step - loss: 1.1557 - acc: 0.7290 - val_loss: 1.2133 - val_acc: 0.7128\n",
      "Epoch 5/6\n",
      "8518/8518 [==============================] - 69s 8ms/step - loss: 1.0440 - acc: 0.7461 - val_loss: 1.1370 - val_acc: 0.7202\n",
      "Epoch 6/6\n",
      "8518/8518 [==============================] - 64s 8ms/step - loss: 0.9680 - acc: 0.7591 - val_loss: 1.0830 - val_acc: 0.7360\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Activation, Conv1D, GlobalMaxPooling1D\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Lambda\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "\n",
    "example_count,sequence_len=vectorized_data_padded.shape\n",
    "example_count,class_count=classes_1hot.shape\n",
    "\n",
    "vector_size=pretrained.shape[1] # embedding dim (\"hidden layer\") must be the same as in the pretrained model\n",
    "kernels = 20\n",
    "window_size = 2 # How many words a kernel sees at a time\n",
    "\n",
    "inp=Input(shape=(sequence_len,))\n",
    "embeddings=Embedding(len(vocabulary), vector_size, mask_zero=False, weights=[pretrained], trainable=False)(inp)\n",
    "cnn = Conv1D(kernels,window_size,padding='valid',activation='relu',strides=1)(embeddings)\n",
    "pooling = GlobalMaxPooling1D()(cnn)\n",
    "outp=Dense(class_count, activation=\"softmax\")(pooling)\n",
    "model=Model(inputs=[inp], outputs=[outp])\n",
    "\n",
    "optimizer=Adam(lr=0.001) # define the learning rate\n",
    "model.compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "# This is our model for outputting the time step wise kernel activations.\n",
    "cnn_out_model=Model(inputs=[inp], outputs=[cnn])\n",
    "# We have to compile the model, but we nerver train it directly\n",
    "cnn_out_model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# train\n",
    "hist=model.fit(vectorized_data_padded,classes_1hot,batch_size=50,verbose=1,epochs=6,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "1. We are using ReLU activation as it simplifies our life\n",
    "2. The word embeddings are now fixed, i.e. the training algorithm is not allowed to change the pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History: [0.5649419268307992, 0.6135163749032186, 0.7001056020967308, 0.7127771916963482, 0.7201689624610144, 0.7360084515061021]\n",
      "Max accuracy: 0.7360084515061021\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"History:\",hist.history[\"val_acc\"])\n",
    "print(\"Max accuracy:\",numpy.max(hist.history[\"val_acc\"]))\n",
    "plt.ylim(0.50,1.0)\n",
    "plt.plot(hist.history[\"val_acc\"],label=\"Validation set accuracy\")\n",
    "plt.plot(hist.history[\"acc\"],label=\"Training set accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make predictions for the whole training and validation data to see what type of bigrams each kernel has learnt to recognize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "947/947 [==============================] - 3s 3ms/step\n",
      "Predictions shape: (947, 969, 20)\n"
     ]
    }
   ],
   "source": [
    "input_data = hist.validation_data[0] # Use vectorized_data_padded if you want activations for the training data as well\n",
    "predictions = cnn_out_model.predict(input_data, verbose=1, batch_size=64)\n",
    "print(\"Predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings from the model: (19497, 300)\n",
      "Kernels: (2, 300, 20)\n",
      "Kernel 0:\n",
      "net loss | net loss | net loss | net loss | net loss | net loss | net loss | net loss | net loss | net loss\n",
      "Hypothetical maximum activation 0: net loss [1.7489415 2.5665832] \n",
      "\n",
      "Kernel 1:\n",
      "trade deficit | trade deficit | trade deficit | trade deficit | trade deficit | trade deficit | trade deficit | trade deficit | trade deficit | trade deficit\n",
      "Hypothetical maximum activation 1: trade rates [3.418724  1.9348184] \n",
      "\n",
      "Kernel 2:\n",
      "OF blah | OF blah | OF blah | OF blah | OF blah | OF blah | OF blah | FOR blah | FOR blah | FOR blah\n",
      "Hypothetical maximum activation 2: FOR blah [0.7164392  0.96077096] \n",
      "\n",
      "Kernel 3:\n",
      "the acquisition | the acquisition | the acquisition | the acquisition | the acquisition | the acquisition | the acquisition | the acquisition | the acquisition | the acquisition\n",
      "Hypothetical maximum activation 3: outstanding acquisition [0.79193604 3.0611641 ] \n",
      "\n",
      "Kernel 4:\n",
      "said He | said He | said He | said He | said He | said He | said He | said He | said He | said He\n",
      "Hypothetical maximum activation 4: said He [1.2809348 1.7220732] \n",
      "\n",
      "Kernel 5:\n",
      "record March | record March | record March | record March | record March | record March | record March | record March | record March | record March\n",
      "Hypothetical maximum activation 5: record March [2.1594095  0.72181445] \n",
      "\n",
      "Kernel 6:\n",
      "Group Inc | Group Inc | Group Inc | Group Inc | Group Inc | Group Inc | Group Inc | Group Inc | Group Inc | Group Inc\n",
      "Hypothetical maximum activation 6: Petroleum Inc [1.3775557 3.2680314] \n",
      "\n",
      "Kernel 7:\n",
      "crude oil | crude oil | crude oil | crude oil | crude oil | crude oil | crude oil | crude oil | crude oil | crude oil\n",
      "Hypothetical maximum activation 7: coffee oil [2.0621421 3.7183118] \n",
      "\n",
      "Kernel 8:\n",
      "white sugar | white sugar | white sugar | white sugar | imports sugar | raw sugar | cane sugar | import sugar | industrial sugar | German sugar\n",
      "Hypothetical maximum activation 8: gold sugar [2.4020514 4.5699334] \n",
      "\n",
      "Kernel 9:\n",
      "stock shares | 60 shares | 33 shares | 30 shares | 30 shares | 16 shares | 31 shares | 17 shares | cash shares | remaining shares\n",
      "Hypothetical maximum activation 9: 40 shares [0.78917795 1.4012363 ] \n",
      "\n",
      "Kernel 10:\n",
      "<SPECIAL> <SPECIAL> | <SPECIAL> <SPECIAL> | <SPECIAL> <SPECIAL> | <SPECIAL> <SPECIAL> | <SPECIAL> <SPECIAL> | <SPECIAL> <SPECIAL> | <SPECIAL> <SPECIAL> | <SPECIAL> <SPECIAL> | <SPECIAL> <SPECIAL> | <SPECIAL> <SPECIAL>\n",
      "Hypothetical maximum activation 10: <SPECIAL> <SPECIAL> [0.32878357 0.34195405] \n",
      "\n",
      "Kernel 11:\n",
      "vs 000 | vs 000 | vs 000 | vs 000 | vs 000 | vs 000 | vs 000 | vs 000 | vs 000 | vs 000\n",
      "Hypothetical maximum activation 11: vs 000 [1.9515483 1.272981 ] \n",
      "\n",
      "Kernel 12:\n",
      "it sold | it sold | it sold | it sold | it sold | it sold | it sold | it sold | it sold | it bought\n",
      "Hypothetical maximum activation 12: it sold [1.529038  0.9540558] \n",
      "\n",
      "Kernel 13:\n",
      "March 31 | March 31 | March 31 | March 31 | March 31 | March 31 | March 31 | March 31 | March 31 | March 31\n",
      "Hypothetical maximum activation 13: March 31 [0.7825295  0.82175744] \n",
      "\n",
      "Kernel 14:\n",
      "37 vs | 37 vs | 37 vs | 37 vs | 37 vs | 37 vs | 37 vs | 46 vs | 46 vs | 46 vs\n",
      "Hypothetical maximum activation 14: 42 vs [0.9995268 1.8607804] \n",
      "\n",
      "Kernel 15:\n",
      "000 barrels | 000 barrels | 000 barrels | 000 barrels | 000 barrels | 500 barrels | 50 barrel | 50 barrel | 50 barrel | 50 barrel\n",
      "Hypothetical maximum activation 15: blah barrels [1.1947472 2.0474153] \n",
      "\n",
      "Kernel 16:\n",
      "rate rises | rate blah | rate cuts | rate cuts | rate unchanged | rate shifts | rate increases | rate rollback | rate futures | rate reductions\n",
      "Hypothetical maximum activation 16: rate split [3.558523 1.329798] \n",
      "\n",
      "Kernel 17:\n",
      "per share | per share | per share | per share | per share | per share | per share | per share | per share | per share\n",
      "Hypothetical maximum activation 17: per share [0.973922 2.742912] \n",
      "\n",
      "Kernel 18:\n",
      "government would | government would | government would | government would | legislation would | transaction would | committee would | agreement would | proposal would | transactions would\n",
      "Hypothetical maximum activation 18: government would [1.258998 1.267751] \n",
      "\n",
      "Kernel 19:\n",
      "000 vs | 000 vs | 000 vs | 000 vs | 000 vs | 000 vs | 000 vs | 000 vs | 000 vs | 000 vs\n",
      "Hypothetical maximum activation 19: 000 vs [1.2356659 2.0590339] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = model.layers[1].get_weights()[0]\n",
    "print(\"Word embeddings from the model:\", word_embeddings.shape)\n",
    "print(\"Kernels:\", model.layers[2].get_weights()[0].shape)\n",
    "for kernel_index in range(model.layers[2].get_weights()[0].shape[-1]):\n",
    "    kernel = model.layers[2].get_weights()[0][:,:,kernel_index] + model.layers[2].get_weights()[1][kernel_index]\n",
    "\n",
    "    # Hypothetical highest activations\n",
    "    activations = numpy.dot(kernel, word_embeddings.T)\n",
    "    best_word_indices = numpy.argmax(activations, axis=-1)\n",
    "    \n",
    "    # Highest activations seen in the validation data\n",
    "    max_time_steps = numpy.argmax(predictions[:,:,kernel_index], axis=-1)\n",
    "    max_activations = numpy.max(predictions[:,:,kernel_index], axis=-1)\n",
    "    best_sentences = numpy.argsort(-max_activations)\n",
    "    \n",
    "    best_ngrams = [input_data[best_sentences[nth]][max_time_steps[best_sentences[nth]]:max_time_steps[best_sentences[nth]]+window_size] for nth in range(10)]\n",
    "    best_ngrams = [' '.join([inversed_vocabulary[i] for i in best]) for best in best_ngrams]\n",
    "    best_ngrams = ' | '.join(best_ngrams)\n",
    " \n",
    "    print('Kernel %s:' % kernel_index)\n",
    "    print(best_ngrams)\n",
    "    print('Hypothetical maximum activation %s:' % kernel_index, ' '.join([inversed_vocabulary[wi] for wi in best_word_indices]), numpy.max(activations, axis=-1), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at some of the kernels, e.g. kernel 10:\n",
    "\n",
    "Worst script | incoherent script | worst acting | worst acting | worst acting | abysmal screenplay | worst written | poorly scripted | poorly filmed | poorly directed\n",
    "Hypothetical maximum activation 10: worst script [1.0209291 0.7113825]\n",
    "\n",
    "* The activating bigram seems to be a negative adjective and a movie related concept\n",
    "* The hypothetical maximum activation we can generate with the given vocabulary is \"worst script\", which is very close to the first actual hit, however, this is not always the case:\n",
    "\n",
    "Kernel 13:\n",
    "movie sorry | movie Sorry | movie Oh | movie Oh | movie Oh | movie oh | movie oh | movie fails | movie fails | movie fails\n",
    "\n",
    "Hypothetical maximum activation 13: porn oops [0.6134886 1.025104 ]\n",
    "\n",
    "Sometimes the kernels are uninterpretable or they make unrealistic assumptions about the the shape of the word embedding space.\n",
    "\n",
    "* Window size does not force the kernel to learn certain length n-grams (only sets an upper boundary):\n",
    "\n",
    "Kernel 19:\n",
    "Great soundtrack | Great film | Great film | great soundtrack | great soundtrack | Great movie | Great Movies | great film | great film | great film\n",
    "\n",
    "Hypothetical maximum activation 19: Great worksheets [1.0821922 0.6044347]\n",
    "\n",
    "If we look at the maximum activations for each slot in the above kernel, we notice that the first word has almost twice as high activation as the second one. This means that basically the first word has to be \"great\" and the second word can be almost anything, i.e. the kernel is only detecting unigrams.\n",
    "\n",
    "* Looking at the kernel activations does not tell us anything about the kernel importance or relatedness to a certain output (e.g. positive review). To analyze these aspects of the network we have to look into the dense layers following the convolutional layer. This, however, is not straightforward as both CNN kernel activation strengths and dense layer weights should be analyzed together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
