{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-words document classification\n",
    "\n",
    "What will happen on Reuters?\n",
    "\n",
    "* How to read the original Reuters data in: [read_news.ipynb](read_news.ipynb)\n",
    "* Reuters news with about 10000 news articles classified into 66 classes\n",
    "* We only keep classes with at least 5 examples, end up with 51 classes\n",
    "* How well can we do on a 51-class classification problem with our BoW?\n",
    "\n",
    "This is the exact same code as in the original bag-of-words, just file names changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '&#2;\\nUNITED COMPANIES &lt;UNCF> DECLARES STOCK DIVIDEND\\nBATON ROUGE, La, March 6 - United Companies Financial Corp\\nsaid its board declared a two pct stock dividend payable APril\\neight to holders of record March 17.\\nThe board also declared a regular quarterly cash dividend\\nof 12.5 cts payable April one to holders of record March 16.\\nReuter\\n&#3;', 'class': 'earn'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "random.seed(0)\n",
    "with open(\"data/reuters_51cls.json\") as f:\n",
    "    data=json.load(f)\n",
    "random.shuffle(data) #play it safe!\n",
    "print(data[0]) #Every item is a dictionary with `text` and `class` keys, here's one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['&#2;\\nUNITED COMPANIES &lt;UNCF> DECLARES STOCK DIVIDEND\\nBATON ROUGE, La, March 6 - United Companies Financial Corp\\nsaid its board declared a two pct stock dividend payable APril\\neight to holders of record March 17.\\nThe board also declared a regular quarterly cash dividend\\nof 12.5 cts payable April one to holders of record March 16.\\nReuter\\n&#3;', '&#2;\\nCANBRA FOODS SETS SPECIAL FIVE DLR/SHR PAYOUT\\nLETHBRIDGE, Alberta, March 16 - &lt;Canbra Foods Ltd>, earlier\\nreporting a 1986 net profit against a year-ago loss, said it\\ndeclared a special, one-time dividend of five dlrs per common\\nshare, pay March 31, record March 26.\\nCanbra said it set the special payout to allow shareholders\\nto participate in the gain on the sale of unit Stafford Foods\\nLtd in November, 1986, as well as the company\\'s \"unusually\\nprofitable performance\" in 1986.\\nCanbra earlier reported 1986 net earnings of 4.2 mln dlrs,\\nexcluding a 1.3 mln dlr gain on the Stafford sale, compared to\\na year-ago loss of 1.5 mln dlrs.\\nReuter\\n&#3;']\n",
      "['earn', 'earn']\n"
     ]
    }
   ],
   "source": [
    "# We need to gather the texts, into a list\n",
    "texts=[one_example[\"text\"] for one_example in data]\n",
    "labels=[one_example[\"class\"] for one_example in data]\n",
    "print(texts[:2])\n",
    "print(labels[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape= (9465, 29208)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "\n",
    "vectorizer=CountVectorizer(max_features=100000,binary=True,ngram_range=(1,1)) #unigrams etc., binaryn voi ottaa pois\n",
    "feature_matrix=vectorizer.fit_transform(texts)\n",
    "print(\"shape=\",feature_matrix.shape)\n",
    "#print(feature_matrix.todense())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the feature matrix done! Next thing we need is the class labels to be predicted in one-hot encoding. This means:\n",
    "\n",
    "* one row for every example\n",
    "* one column for every possible class label\n",
    "* exactly one column has 1 for every example, corresponding to the desired class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_numbers shape= (9465,)\n",
      "class_numbers [11 11 11 ... 11  0  0]\n",
      "class labels ['acq' 'alum' 'bop' 'carcass' 'cocoa' 'coffee' 'copper' 'cotton' 'cpi'\n",
      " 'crude' 'dlr' 'earn' 'fuel' 'gas' 'gnp' 'gold' 'grain' 'heat' 'housing'\n",
      " 'income' 'instal-debt' 'interest' 'ipi' 'iron-steel' 'jobs' 'lead' 'lei'\n",
      " 'livestock' 'lumber' 'meal-feed' 'money-fx' 'money-supply' 'nat-gas'\n",
      " 'oilseed' 'orange' 'pet-chem' 'potato' 'reserves' 'retail' 'rubber'\n",
      " 'ship' 'silver' 'strategic-metal' 'sugar' 'tea' 'tin' 'trade' 'veg-oil'\n",
      " 'wpi' 'yen' 'zinc']\n",
      "classes_1hot [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "label_encoder=LabelEncoder() #Turns class labels into integers\n",
    "one_hot_encoder=OneHotEncoder(sparse=False) #Turns class integers into one-hot encoding\n",
    "class_numbers=label_encoder.fit_transform(labels)\n",
    "print(\"class_numbers shape=\",class_numbers.shape)\n",
    "print(\"class_numbers\",class_numbers)\n",
    "print(\"class labels\",label_encoder.classes_)\n",
    "#And now yet the one-hot encoding\n",
    "classes_1hot=one_hot_encoder.fit_transform(class_numbers.reshape(-1,1))\n",
    "print(\"classes_1hot\",classes_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marsalv/.local/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8518 samples, validate on 947 samples\n",
      "Epoch 1/2\n",
      "8518/8518 [==============================] - 39s 5ms/step - loss: 0.9820 - acc: 0.8164 - val_loss: 0.4030 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.40296, saving model to models/reuters_51cls_bow.weights.h5\n",
      "Epoch 2/2\n",
      "8518/8518 [==============================] - 38s 4ms/step - loss: 0.1480 - acc: 0.9804 - val_loss: 0.2625 - val_acc: 0.9493\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.40296 to 0.26253, saving model to models/reuters_51cls_bow.weights.h5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def save_model(file_name,model,label_encoder,vectorizer):\n",
    "    \"\"\"Saves model structure and vocabularies\"\"\"\n",
    "    model_json = model.to_json()\n",
    "    with open(file_name+\".model.json\", \"w\") as f:\n",
    "        print(model_json,file=f)\n",
    "    with open(file_name+\".vocabularies.json\",\"w\") as f:\n",
    "        classes=list(label_encoder.classes_)\n",
    "        vocab=dict(((str(w),int(idx)) for w,idx in vectorizer.vocabulary_.items()))\n",
    "        json.dump((classes,vocab),f,indent=2)\n",
    "        \n",
    "example_count,feature_count=feature_matrix.shape\n",
    "example_count,class_count=classes_1hot.shape\n",
    "\n",
    "inp=Input(shape=(feature_count,))\n",
    "hidden=Dense(300,activation=\"tanh\")(inp)\n",
    "outp=Dense(class_count,activation=\"softmax\")(hidden)\n",
    "model=Model(inputs=[inp], outputs=[outp])\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['accuracy']) #sgd on tyhmin optimizer, vaikuttaa paljon tulokseen!!, \"adam\" on parempi, mutta voi joskus mennä ihan sekaisin\n",
    "#googleta ja kokeile eri optimizereja\n",
    "\n",
    "# Save model and vocabularies\n",
    "save_model(\"models/reuters_51cls_bow\",model,label_encoder,vectorizer)\n",
    "# Callback function to save weights during training\n",
    "save_cb=ModelCheckpoint(filepath=\"models/reuters_51cls_bow.weights.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "hist=model.fit(feature_matrix,classes_1hot,batch_size=100,verbose=1,epochs=2,validation_split=0.1,callbacks=[save_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#Validation data used during training:\n",
    "val_instances,val_labels_1hot,_=hist.validation_data\n",
    "\n",
    "print(\"Network output=\",model.predict(val_instances))#network output should add up to 1 (vrt. 0.8 ja 0.2),\n",
    "predictions=numpy.argmax(model.predict(val_instances),axis=1)\n",
    "print(\"Maximum class for each example=\",predictions)#for every row find the max value, rows=validations axis=0, columns=classes axis=1\n",
    "gold=numpy.nonzero(val_labels_1hot)[1] #undo 1-hot encoding #kertoo missä on ei-nolla arvo (1)\n",
    "conf_matrix=confusion_matrix(list(gold),list(predictions)) #confusion matrix (predicted,correcrt) \n",
    "print(conf_matrix)\n",
    "print(classification_report(list(gold),list(predictions),target_names=label_encoder.classes_))\n",
    "#support=kuinka monta kpl olisi pitäinyt löytää\n",
    "#recall=kuinka monta löysi, niistä mitä piti\n",
    "#precision=?\n",
    "#f=precision ja recall yhteensä\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
